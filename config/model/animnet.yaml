_target_: src.projects.speech_animation.pl_animnet.PL_AnimNet
_init_: src.projects.speech_animation.pl_animnet.pre_compute_paddings

debug: ${debug}
video: ${data.video}
audio: ${data.audio}
wanna_fps: 30

# * tag of model
_tag_optional: ${cond:${.data_info.correct_avoffset},'',avoff-}

_tag_audio: ds${data.audio.sliding_window.deepspeech}_${.animnet.encoder.audio.using}

_tag_seq_lstm: lstm
_tag_seq_xfmr: xfmr_d${.animnet.sequential.xfmr.d_model}ff${.animnet.sequential.xfmr.dim_feedforward}e${.animnet.sequential.xfmr.encoder_num_layers}d${.animnet.sequential.xfmr.decoder_num_layers}
_tag_seq_conv: conv_${cond:${.animnet.sequential.conv.causal},causal,conv}
_tag_seq: ${case:${.animnet.sequential.using},conv,${._tag_seq_conv},xfmr,${._tag_seq_xfmr},lstm,${._tag_seq_lstm}}

_tag_dec_morph: flame${.animnet.decoder.verts.morphable.flame.n_exp}
_tag_dec_bs: blend${.animnet.decoder.verts.blendshape.n_components}_${cond:${.animnet.decoder.verts.blendshape.trainable},trainable,fixed}
_tag_dec: ${case:${.animnet.decoder.verts.using},morphable,${._tag_dec_morph},blendshape,${._tag_dec_bs}}

tag: ${._tag_optional}${._tag_audio}-${._tag_seq}-${._tag_dec}

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                    Visualizer                                                    * #
# * ---------------------------------------------------------------------------------------------------------------- * #

visualizer:
  painter: demo_columns
  # tb plot settings
  draw_gap_steps: 200
  draw_grid_size: 256
  # video settings
  video_gap_epochs: 10
  video_grid_size:  256
  video_1st_epoch:  false
  # generate or not
  generate_train: true
  generate_valid: true
  generate_test:  false
  # dump or not
  dump_metrics: true
  dump_audio:   false
  dump_offsets: false
  dump_images:  false
  dump_coeffs:  false
  # overwrite or not
  overwrite_videos: false











# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                  Neural Renderer                                                 * #
# * ---------------------------------------------------------------------------------------------------------------- * #

freeze_renderer: true
neural_renderer:
  load_from:
    path: ""
    possible_names: ["neural_renderer"]
    state_dict_remove_prefix: ["renderer."]
    freeze_loaded: ${...freeze_renderer}

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                      AnimNet                                                     * #
# * ---------------------------------------------------------------------------------------------------------------- * #

data_info:
  src_seq_frames: ${..animnet.src_seq_frames}
  tgt_seq_frames: ${..animnet.tgt_seq_frames}
  src_seq_pads:   ${..animnet.src_seq_pads}
  pad_tgt: false
  correct_avoffset: true

freeze_animnet: false
animnet:
  # output deformation
  deform_from: "idle"
  # sequence length
  src_seq_frames: 20
  tgt_seq_frames: ${.src_seq_frames}
  src_seq_pads: [0, 0]  # should be automaticly computed in pre_compute_paddings
  # audio
  company_audio: "win"  # win | one
  using_audio_feature: "deepspeech"

  finetune_from: null
  freeze_audio_encoder: false
  freeze_seq_module: false

  # * ---------------------------------------------- per-frame encoder --------------------------------------------- * #

  encoder:
    using: ["audio"]
    audio:
      using: "xfmr"
      feature: "deepspeech"
      conv: { out_channels: 64, layer_norm: false, dropout: 0.0 }
      attn: { name: "bah", query_radius: 2, n_layers: 3, memory_size: 128, num_units: 64, smooth: false}
      xfmr: { d_model: 64, n_head: 4, n_enc_layers: 3, n_dec_layers: 1, dropout: 0.1, layer_norm: true }

  # * ---------------------------------------------- sequential module --------------------------------------------- * #

  sequential:
    using: "conv"
    conv:
      causal: true
      hidden_channels: [64, 128, 256]
      kernel_size: [5, 3, 3]
      dilation: 1
      norm_method: none
      dropout: 0.1

    lstm:
      num_layers: 2
      hidden_channels: 256
      dropout: 0.1

    xfmr:
      win_size: 9  # same reception field as conv causal
      d_model: 64
      nhead: 4
      dim_feedforward: 256
      activation: 'relu'
      encoder_num_layers: 3
      decoder_num_layers: 1
      dropout: 0.1

  # * ---------------------------------------------- per-frame decoder --------------------------------------------- * #

  decoder:
    verts:
      using: blendshape

      morphable:
        using: flame
        flame:
          n_shape: 100
          n_exp: 50

      blendshape:
        trainable: true
        using_basis: 'flame'
        n_components: 50
        flame_model_path: ${..morphable.flame.model_path}
        # mlp projection
        shared_mlp: { out_channels: [256, 256] }
        specific_mlp: { hidden_channels: [128] }
        norm_method: "none"
        activation: 'lrelu0.2'


# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                Optimizer settings                                                * #
# * ---------------------------------------------------------------------------------------------------------------- * #

optim_animnet:
  name: "Adam"
  lr: 1e-4
  weight_decay: 1e-8
  lr_scheduler: { name: LambdaLR, interval: epoch, gamma: 0.90, start_iter: 30, min_times: 0.1 }

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                       Loss                                                       * #
# * ---------------------------------------------------------------------------------------------------------------- * #

loss:
  rendering:
    lmks_type: fw75
    lmks: 3.0
    eyed: 0.0
    lipd: 2.0
    photo: 2.0
    extra_scale_tex3: 0.2
    # vgg loss for face identity
    face_id: 0.2
    # reg code
    reg_shape: 2e-3
    reg_exp: 2e-4
    reg_tex: 1e-3
    reg_sh9: 1.0
    reg_eye: [5e-2, 5e-2, 100.]
    reg_jaw: [5e-3, 100., 100.]
    # reg smooth
    reg_exp_smooth: 0.2
    reg_jaw_smooth: [0.2, 100.0, 100.0]
    reg_eye_smooth: 1.0
    reg_sh9_smooth: 1.0
    reg_rot_smooth: [50.0, 10.0, 50.0]
    reg_cam_smooth: [10.0, 100.0, 100.0]
    # specific weight for each point
    lmks_weights: [
      # contour left 0 ~ 4
      1.0, 1.0, 1.0, 1.0, 1.0,
      # contour bottom 5 ~ 9
      1.0, 1.0, 1.0, 1.0, 1.0,
      # contour right 10 ~ 14
      1.0, 1.0, 1.0, 1.0, 1.0,
      # eyebrows 15 ~ 20, 21 ~ 26
      0.8, 0.8, 0.8, 0.8, 0.8, 0.8,
      0.8, 0.8, 0.8, 0.8, 0.8, 0.8,
      # eyes 27 ~ 30, 31 ~ 34
      0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0,
      # nose 35 ~ 45
      0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,
      # nose inner holes
      0.0, 0.0,
      # lip outter 46 ~ 51
      2.0, 1.0, 1.5, 2.0, 1.5, 1.0,
      # lip outter 52 ~ 57
      2.0, 1.0, 1.5, 2.0, 1.5, 1.0,
      # lip inner 58 ~ 60
      2.0, 2.0, 2.0,
      # lip inner 61 ~ 63
      2.0, 2.0, 2.0,
      # nose center 64
      0.0,
      # eyes more 65 ~ 68, 69 ~ 72, 73, 74
      0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0,
      # eyeballs
      0.0, 0.0,
    ]
  # mesh
  mesh:
    part: face_noeyeballs
    scale_pos: 1.0
    scale_motion: 5.0
    scale_inv_part: 0.1
    scale_remained: 0.1
    scale_lip_diff: 1.0
