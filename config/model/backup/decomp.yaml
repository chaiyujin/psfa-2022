_target_: src.projects.decomp.pl.PL_Wrapper

debug: ${debug}
video: ${data.video}
audio: ${data.audio}
wanna_fps: 30

tag: "test"

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                    Visualizer                                                    * #
# * ---------------------------------------------------------------------------------------------------------------- * #

visualizer:
  painter:
    - demo_duplex
    - demo_duplex_comp
    - demo_duplex_audio
    - demo_duplex_comp_audio
    - demo_swap_cycle
    - demo_recons
    - demo_recons_audio
    - demo_recons_coma
    - demo_audio_style
  # tb plot settings
  draw_gap_steps: 500
  draw_grid_size: 256
  # video settings
  video_gap_epochs: 1
  video_grid_size: 256
  video_1st_epoch: true
  # generate or not
  generate_train: true
  generate_valid: true
  generate_test:  true
  # dump or not
  dump_metrics: true
  dump_audio:   false
  dump_offsets: false
  dump_images:  false
  dump_coeffs:  false
  # overwrite or not
  overwrite_videos: false

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                      AnimNet                                                     * #
# * ---------------------------------------------------------------------------------------------------------------- * #

data_info:
  src_seq_frames: 1
  tgt_seq_frames: ${.src_seq_frames}
  src_seq_pads: [0, 0]  # should be automaticly computed in pre_compute_paddings
  pad_tgt: false
  # audio
  company_audio: "win"  # win | one
  using_audio_feature: "deepspeech"


# * ---------------------------------------------- per-frame encoder --------------------------------------------- * #

encoder:
  using_audio: false
  using_seq: false

  audio:
    using: "xfmr"
    feature: "deepspeech"
    conv: { out_channels: 128, layer_norm: true, dropout: 0.1 }
    attn: { name: "bah", query_radius: 2, n_layers: 3, memory_size: 128, num_units: 128, smooth: false}
    xfmr: { d_model: 128, n_head: 4, n_enc_layers: 3, n_dec_layers: 1, dropout: 0.1, layer_norm: true }

  style:
    using: m2i
    part: face_lower
    m2i: {mode: nearest, image_size: 64, nfc: 32}
    out_channels: 128

  content:
    using: m2i
    part: face_lower
    m2i: {mode: nearest, image_size: 64, nfc: 32}
    out_channels: 128

# * ---------------------------------------------- per-frame decoder --------------------------------------------- * #

decoder:

  offsets:
    using: blendshape
    blendshape:
      trainable: true
      using_basis: 'flame'
      n_components: 50
      flame_model_path: ${..morphable.flame.model_path}
      # mlp projection
      shared_mlp: { out_channels: [256, 256] }
      specific_mlp: { hidden_channels: [128] }
      norm_method: "none"
      activation: 'lrelu0.2'

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                Optimizer settings                                                * #
# * ---------------------------------------------------------------------------------------------------------------- * #

load_from: null
freeze_decoupler: false
freeze_recoupler: false
freeze_audio_encoder: false

optim:
  name: "Adam"
  lr: 1e-4
  weight_decay: 1e-8

# * ---------------------------------------------------------------------------------------------------------------- * #
# *                                                       Loss                                                       * #
# * ---------------------------------------------------------------------------------------------------------------- * #

loss:
  mesh:
    part: face_neye
    pos: 1.0
    motion: 5.0
    non_face: 1e-3
    lip_diff: 1.0
  rec: 1
  swp: 5
  cyc: 1
  reg_z_ctt_close: 5.0
  reg_z_sty_close: 5.0
  reg_z_aud_close: 5.0
  reg_z_ctt_coma: 1.0
  audio: 2.0
  coma: 1.0
